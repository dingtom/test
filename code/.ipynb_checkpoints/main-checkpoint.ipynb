{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyts==0.7.1 in /home/zut_csi/anaconda3/envs/tomding/lib/python3.8/site-packages (0.7.1)\n",
      "Requirement already satisfied: numpy>=1.8.2scipy>=0.13.3scikit-learn>=0.17.0future>=0.13.1 in /home/zut_csi/anaconda3/envs/tomding/lib/python3.8/site-packages (from pyts==0.7.1) (1.19.4)\n",
      "model name\t: Intel(R) Core(TM) i9-10900F CPU @ 2.80GHz\n",
      "Mon Dec 21 08:22:26 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 455.45.01    Driver Version: 455.45.01    CUDA Version: 11.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 3070    Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "|  0%   42C    P8    18W / 270W |    589MiB /  7979MiB |     12%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1154      G   /usr/lib/xorg/Xorg                 24MiB |\n",
      "|    0   N/A  N/A      1203      G   /usr/bin/gnome-shell               53MiB |\n",
      "|    0   N/A  N/A      1505      G   /usr/lib/xorg/Xorg                145MiB |\n",
      "|    0   N/A  N/A      1633      G   /usr/bin/gnome-shell               32MiB |\n",
      "|    0   N/A  N/A      1657      G   ...mviewer/tv_bin/TeamViewer       17MiB |\n",
      "|    0   N/A  N/A     24384      C   ...3/envs/tomding/bin/python      303MiB |\n",
      "|    0   N/A  N/A     31380      G   /usr/lib/firefox/firefox            3MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import json\n",
    "import re\n",
    "import math\n",
    "import os\n",
    "import threading\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import scipy.io as scio\n",
    "\n",
    "from scipy import interpolate\n",
    "import scipy.signal as signal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "import scipy.io.wavfile as wav\n",
    "from scipy.fftpack import fft\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "!pip install pyts==0.7.1\n",
    "from pyts.image import *\n",
    "\n",
    "from extract_csi import extract_csi, get_scaled_csi\n",
    "from data_augument import * # data_crop, down_sampling, moving_average, add_jitter, add_scaling\n",
    "from get_files_info import *\n",
    "\n",
    "\n",
    "!cat /proc/cpuinfo | grep 'model name' |uniq\n",
    "!nvidia-smi\n",
    "# 设置GPU内存按需分配\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "raw_file_path = r'../data_qinghua/20181112/user2' \n",
    "save_path = r'../data_processed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取CSI中想要的部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 提取每个天线对上的CSI\n",
    "# def process_data(raw_file_path, save_path):\n",
    "#     X = {}\n",
    "#     thread_list= []\n",
    "#     for f in tqdm(os.listdir(raw_file_path)):             \n",
    "#         if f.endswith('.dat'):\n",
    "#             def processor():\n",
    "#                 file_name = os.path.join(raw_file_path, f)\n",
    "#                 extracted_data = extract_csi(file_name)\n",
    "#                 # print('processing {} the length of this file is:{}'.format(file_name, len(extracted_data)))\n",
    "#                 tx, rx, sub = extracted_data[0]['csi'].shape\n",
    "#                 data_csi = np.zeros((len(extracted_data), tx, rx, sub), dtype=np.complex64)\n",
    "#                 # qinghua (1938, 1, 3, 30)  ;    self\n",
    "#                 for i in range(len(extracted_data)):\n",
    "#                     data_csi[i] = get_scaled_csi(extracted_data[i])\n",
    "#                 data_csi = np.clip(np.abs(np.squeeze(data_csi)), 1e-8, 1e100).reshape(-1, tx*rx, 30)   \n",
    "#                 data = np.zeros((data_csi.shape[0], tx*rx))  # N*4\n",
    "#                 for ant in range(tx*rx):  # 每个天线对上的CSI变化趋势相同,为节约计算这里选择天线对即可\n",
    "#                     data_csi_ant = data_csi[:, ant, :]\n",
    "#                     b, a = signal.butter(5, 4*2/30, 'low')\n",
    "#                     var_max = 0\n",
    "#                     s_max = None\n",
    "#                     for s in range(30):\n",
    "#                         carrier_data = signal.lfilter(\n",
    "#                             b, a, data_csi_ant[:, s])  # N*1\n",
    "#                         length = len(carrier_data)\n",
    "#                         var_temp = np.var(carrier_data[length//5:3*length//5])\n",
    "#                         if var_max < var_temp:\n",
    "#                             var_max = var_temp\n",
    "#                             s_max = carrier_data\n",
    "#                     data[:, ant] = s_max\n",
    "#                 scio.savemat(os.path.join(save_path, f.split('.')[0]+'.mat'), {'csi': data})\n",
    "#                 X[f] = data\n",
    "#             t = threading.Thread(target=processor, args=())                              \n",
    "#             t.setDaemon(True)  # 设置为守护线程                              \n",
    "#             thread_list.append(t)\n",
    "            \n",
    "#     for t in thread_list:         \n",
    "#         t.start()  # 启动线程     \n",
    "#     for t in thread_list: \n",
    "#         t.join()  # 等待子线程结束\n",
    "#     print('-----------------------------------all raw file processed---------------------------------')\n",
    "#     # return X\n",
    "# process_data(raw_file_path, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据信息生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-2cebc14d4d23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_label_file_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_wav_file_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_file_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_label_file_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label_file_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_wav_file_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_wav_file_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_label_file_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_wav_file_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tomding/RCNN/code/get_files_info.py\u001b[0m in \u001b[0;36mget_file_list\u001b[0;34m(train_file)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_file_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlabel_f_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mwav_f_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "train_file_path = save_path\n",
    "\n",
    "train_label_file_list, train_wav_file_list = get_file_list(train_file_path)\n",
    "\n",
    "train_label_file_list, test_label_file_list, train_wav_file_list, test_wav_file_list = train_test_split(train_label_file_list, train_wav_file_list, test_size=0.1, random_state=42)\n",
    "\n",
    "train_label_list = get_label_data(train_label_file_list)\n",
    "\n",
    "# 用迭代器的时候需要\n",
    "# train_wav_file_list, validate_wav_file_list, train_label_list, validate_label_list = train_test_split(train_wav_file_list, train_label_list, test_size=0.2, random_state=0)\n",
    "\n",
    "# 每个文件拼音标签的集合\n",
    "with open('label_list.txt', 'w') as f:  \n",
    "    f.write('\\n'.join(train_label_list))  \n",
    "py_list = gen_py_list(train_label_list)  # 拼音的集合\n",
    "\n",
    "with open('pinyin_list.txt', 'w') as f:\n",
    "    f.write('\\n'.join(py_list))  # 保存拼音列表\n",
    "\n",
    "train_file_nums = len(train_wav_file_list)\n",
    "# validate_file_nums = len(validate_wav_file_list)\n",
    "\n",
    "py_list_size = len(py_list)  # 模型输出的维度\n",
    "print('py_list:', py_list)\n",
    "print('train files amount:', len(train_label_list), train_file_nums, 'label amount:', py_list_size)#, 'validate files amount:', len(validate_label_list), validate_file_nums,)\n",
    "\n",
    "# 测试数据\n",
    "\n",
    "\n",
    "# test_file_path = test_save_path # r'/content/drive/My Drive/data_thchs30'\n",
    "# test_label_file_list, test_wav_file_list = get_file_list(test_file_path)\n",
    "\n",
    "test_label_list = get_label_data(test_label_file_list)\n",
    "print('test files amount:',len(test_label_file_list), len(test_wav_file_list))\n",
    "test_data_num = len(test_label_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 开始训练、测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_size=64  \n",
    "batch_size = 16\n",
    "logs_path = '../logs'\n",
    "\n",
    "input_size=(None, image_size, 1)\n",
    "base_model, ctc_model = create_model(input_size, output_size=py_list_size) \n",
    "print(ctc_model.summary())\n",
    "\n",
    "# keras.utils.plot_model(base_model, show_shapes=True)\n",
    "\n",
    "if not os.path.exists(logs_path):  # 判断保存模型的目录是否存在\n",
    "    os.makedirs(logs_path)  # 如果不存在，就新建一个，避免之后保存模型的时候炸掉\n",
    "\n",
    "# train_batch_gen = get_batch_generator(batch_size, train_wav_file_list, train_label_list, py_list, image_size)\n",
    "# validate_batch_gen = get_batch_generator(batch_size, validate_wav_file_list, validate_label_list, py_list, image_size)\n",
    "# input_data = next(train_batch_gen)[0]\n",
    "# plt.imshow(input_data['the_inputs'][0].T[0])\n",
    "# plt.show()\n",
    "# print(input_data['the_inputs'].shape, input_data['the_labels'].shape, input_data['input_length'].shape, input_data['label_length'].shape)\n",
    "\n",
    "train_data = get_train_data(train_wav_file_list, train_label_list, py_list, image_size)\n",
    "\n",
    "cb = []\n",
    "cb.append(keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0))\n",
    "# 当监测值不再改善时，该回调函数将中止训练可防止过拟合\n",
    "cb.append(keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=50, verbose=1, mode='auto'))\n",
    "# his = ctc_model.fit_generator(train_batch_gen, verbose=1, steps_per_epoch=train_file_nums//batch_size, validation_data=validate_batch_gen, validation_steps=validate_file_nums//batch_size, epochs=1000, callbacks=cb)  \n",
    "\n",
    "his = ctc_model.fit(train_data[0], train_data[1], validation_split=0.1, batch_size=128, epochs=1000, callbacks=cb)  # callback的epoch都是对fit里的参数来说\n",
    "\n",
    "#  保存模型结构及权重\n",
    "ctc_model.save_weights(r'save_weights.h5')\n",
    "with open(r'model_struct.json', 'w') as f:\n",
    "    json_string = base_model.to_json()\n",
    "    f.write(json_string)  # 保存模型信息\n",
    "print('模型结构及权重已保存')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载权重\n",
    "with open(r'model_struct.json') as f:\n",
    "    model_struct = f.read()\n",
    "test_model = keras.models.model_from_json(model_struct)\n",
    "test_model.load_weights(r'save_weights.h5')\n",
    "# model = keras.models.load_model('all_model.h5')\n",
    "print('模型已加载')\n",
    "py_list = []\n",
    "with open(r'pinyin_list.txt', 'r') as f:\n",
    "    contents = f.readlines()\n",
    "for line in contents:\n",
    "    i = line.strip('\\n')\n",
    "    py_list.append(i)\n",
    "print('py_list已加载')\n",
    "\n",
    "# 对模型进行评价\n",
    "\n",
    "\n",
    "def evaluate(kind, wavs, labels):\n",
    "    data_num = len(wavs)\n",
    "    error_cnt = 0\n",
    "    for i in range(data_num):\n",
    "        pre = test_model.predict(wavs[i])  # (1, 20, 11)\n",
    "        pre_index, pre_label = decode_ctc(pre, py_list)  # ['5']\n",
    "        try:\n",
    "            pre_label = int(pre_label[0])\n",
    "        except:\n",
    "            pre_label = None\n",
    "        label = int(py_list[labels[i]])\n",
    "        if label != pre_label:\n",
    "            error_cnt += 1\n",
    "            print('真实标签：', label, '预测结果', pre_label)\n",
    "    print('{}:样本数{}错误数{}准确率：{:%}'.format(\n",
    "        kind, data_num, error_cnt, (1-error_cnt/data_num)))\n",
    "\n",
    "\n",
    "# 训练集\n",
    "train_wavs, train_labels = get_test_data(image_size, train_wav_file_list, train_label_list, py_list)\n",
    "# 测试集\n",
    "test_wavs, test_labels = get_test_data(image_size, test_wav_file_list, test_label_list, py_list)\n",
    "\n",
    "evaluate('trian', train_wavs, train_labels)\n",
    "evaluate('test', test_wavs, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tomding",
   "language": "python",
   "name": "tomding"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
